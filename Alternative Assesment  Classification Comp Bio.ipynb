{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Reading Process </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cancer = pd.read_csv('Prostate_Cancer2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 100 non-null    int64  \n",
      " 1   diagnosis_result   100 non-null    object \n",
      " 2   radius             100 non-null    int64  \n",
      " 3   texture            100 non-null    int64  \n",
      " 4   perimeter          100 non-null    int64  \n",
      " 5   area               100 non-null    int64  \n",
      " 6   smoothness         100 non-null    float64\n",
      " 7   compactness        100 non-null    float64\n",
      " 8   symmetry           100 non-null    float64\n",
      " 9   fractal_dimension  100 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "Cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>954</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>386</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "      <td>477</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>120</td>\n",
       "      <td>1040</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>578</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>88</td>\n",
       "      <td>520</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>476</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id diagnosis_result  radius  texture  perimeter  area  smoothness  \\\n",
       "0   1                M      23       12        151   954       0.143   \n",
       "1   2                B       9       13        133  1326       0.143   \n",
       "2   3                M      21       27        130  1203       0.125   \n",
       "3   4                M      14       16         78   386       0.070   \n",
       "4   5                M       9       19        135  1297       0.141   \n",
       "5   6                B      25       25         83   477       0.128   \n",
       "6   7                M      16       26        120  1040       0.095   \n",
       "7   8                M      15       18         90   578       0.119   \n",
       "8   9                M      19       24         88   520       0.127   \n",
       "9  10                M      25       11         84   476       0.119   \n",
       "\n",
       "   compactness  symmetry  fractal_dimension  \n",
       "0        0.278     0.242              0.079  \n",
       "1        0.079     0.181              0.057  \n",
       "2        0.160     0.207              0.060  \n",
       "3        0.284     0.260              0.097  \n",
       "4        0.133     0.181              0.059  \n",
       "5        0.170     0.209              0.076  \n",
       "6        0.109     0.179              0.057  \n",
       "7        0.165     0.220              0.075  \n",
       "8        0.193     0.235              0.074  \n",
       "9        0.240     0.203              0.082  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>1264</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>B</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>78</td>\n",
       "      <td>451</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>B</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>295</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>B</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>413</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>94</td>\n",
       "      <td>643</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id diagnosis_result  radius  texture  perimeter  area  smoothness  \\\n",
       "95   96                M      23       16        132  1264       0.091   \n",
       "96   97                B      22       14         78   451       0.105   \n",
       "97   98                B      19       27         62   295       0.102   \n",
       "98   99                B      21       24         74   413       0.090   \n",
       "99  100                M      16       27         94   643       0.098   \n",
       "\n",
       "    compactness  symmetry  fractal_dimension  \n",
       "95        0.131     0.210              0.056  \n",
       "96        0.071     0.190              0.066  \n",
       "97        0.053     0.135              0.069  \n",
       "98        0.075     0.162              0.066  \n",
       "99        0.114     0.188              0.064  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>96.780000</td>\n",
       "      <td>702.880000</td>\n",
       "      <td>0.102730</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.193170</td>\n",
       "      <td>0.064690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.011492</td>\n",
       "      <td>4.879094</td>\n",
       "      <td>5.192954</td>\n",
       "      <td>23.676089</td>\n",
       "      <td>319.710895</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.061144</td>\n",
       "      <td>0.030785</td>\n",
       "      <td>0.008151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>476.750000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>114.250000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>1878.000000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      radius     texture   perimeter         area  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000   100.000000   \n",
       "mean    50.500000   16.850000   18.230000   96.780000   702.880000   \n",
       "std     29.011492    4.879094    5.192954   23.676089   319.710895   \n",
       "min      1.000000    9.000000   11.000000   52.000000   202.000000   \n",
       "25%     25.750000   12.000000   14.000000   82.500000   476.750000   \n",
       "50%     50.500000   17.000000   17.500000   94.000000   644.000000   \n",
       "75%     75.250000   21.000000   22.250000  114.250000   917.000000   \n",
       "max    100.000000   25.000000   27.000000  172.000000  1878.000000   \n",
       "\n",
       "       smoothness  compactness    symmetry  fractal_dimension  \n",
       "count  100.000000   100.000000  100.000000         100.000000  \n",
       "mean     0.102730     0.126700    0.193170           0.064690  \n",
       "std      0.014642     0.061144    0.030785           0.008151  \n",
       "min      0.070000     0.038000    0.135000           0.053000  \n",
       "25%      0.093500     0.080500    0.172000           0.059000  \n",
       "50%      0.102000     0.118500    0.190000           0.063000  \n",
       "75%      0.112000     0.157000    0.209000           0.069000  \n",
       "max      0.143000     0.345000    0.304000           0.097000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis_result', 'radius', 'texture', 'perimeter', 'area',\n",
       "       'smoothness', 'compactness', 'symmetry', 'fractal_dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diagnosis_result is the most important column for us. Because we'll classify datas depend on this column.\n",
    "We have to integers for classification. Therefore, we must convert them from object to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cancer.diagnosis_result = [1 if each == 'M' else 0 for each in Cancer.diagnosis_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    62\n",
       "0    38\n",
       "Name: diagnosis_result, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cancer.diagnosis_result.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we assigned 1 and 0 to M and B. Let's some classification! We should assign x and y values for test-train datas split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Cancer.diagnosis_result.values\n",
    "x_data = Cancer.drop(['diagnosis_result'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>954</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>386</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  radius  texture  perimeter  area  smoothness  compactness  symmetry  \\\n",
       "0   1      23       12        151   954       0.143        0.278     0.242   \n",
       "1   2       9       13        133  1326       0.143        0.079     0.181   \n",
       "2   3      21       27        130  1203       0.125        0.160     0.207   \n",
       "3   4      14       16         78   386       0.070        0.284     0.260   \n",
       "4   5       9       19        135  1297       0.141        0.133     0.181   \n",
       "\n",
       "   fractal_dimension  \n",
       "0              0.079  \n",
       "1              0.057  \n",
       "2              0.060  \n",
       "3              0.097  \n",
       "4              0.059  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization: Normalization means all of the values of data, scale between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.875     , 0.0625    , 0.825     , 0.44868735,\n",
       "        1.        , 0.78175896, 0.63313609, 0.59090909],\n",
       "       [0.01010101, 0.        , 0.125     , 0.675     , 0.67064439,\n",
       "        1.        , 0.13355049, 0.27218935, 0.09090909],\n",
       "       [0.02020202, 0.75      , 1.        , 0.65      , 0.59725537,\n",
       "        0.75342466, 0.39739414, 0.4260355 , 0.15909091],\n",
       "       [0.03030303, 0.3125    , 0.3125    , 0.21666667, 0.1097852 ,\n",
       "        0.        , 0.80130293, 0.73964497, 1.        ],\n",
       "       [0.04040404, 0.        , 0.5       , 0.69166667, 0.65334129,\n",
       "        0.97260274, 0.30944625, 0.27218935, 0.13636364],\n",
       "       [0.05050505, 1.        , 0.875     , 0.25833333, 0.16408115,\n",
       "        0.79452055, 0.42996743, 0.43786982, 0.52272727],\n",
       "       [0.06060606, 0.4375    , 0.9375    , 0.56666667, 0.5       ,\n",
       "        0.34246575, 0.23127036, 0.26035503, 0.09090909],\n",
       "       [0.07070707, 0.375     , 0.4375    , 0.31666667, 0.22434368,\n",
       "        0.67123288, 0.41368078, 0.50295858, 0.5       ],\n",
       "       [0.08080808, 0.625     , 0.8125    , 0.3       , 0.18973747,\n",
       "        0.78082192, 0.50488599, 0.59171598, 0.47727273],\n",
       "       [0.09090909, 1.        , 0.        , 0.26666667, 0.16348449,\n",
       "        0.67123288, 0.65798046, 0.40236686, 0.65909091],\n",
       "       [0.1010101 , 0.9375    , 0.625     , 0.425     , 0.35560859,\n",
       "        0.16438356, 0.09446254, 0.10650888, 0.09090909],\n",
       "       [0.11111111, 0.5       , 0.25      , 0.43333333, 0.34546539,\n",
       "        0.36986301, 0.29641694, 0.28994083, 0.18181818],\n",
       "       [0.12121212, 0.3125    , 0.25      , 0.66666667, 0.54952267,\n",
       "        0.36986301, 0.67752443, 0.62130178, 0.56818182],\n",
       "       [0.13131313, 0.1875    , 0.6875    , 0.43333333, 0.34665871,\n",
       "        0.19178082, 0.2019544 , 0.29585799, 0.        ],\n",
       "       [0.14141414, 0.1875    , 0.125     , 0.35      , 0.22434368,\n",
       "        0.5890411 , 0.62214984, 0.4260355 , 0.54545455],\n",
       "       [0.15151515, 0.8125    , 0.5       , 0.375     , 0.27267303,\n",
       "        0.60273973, 0.39739414, 0.56213018, 0.40909091],\n",
       "       [0.16161616, 0.0625    , 0.3125    , 0.35833333, 0.28818616,\n",
       "        0.39726027, 0.11074919, 0.14201183, 0.13636364],\n",
       "       [0.17171717, 0.375     , 0.1875    , 0.46666667, 0.35620525,\n",
       "        0.64383562, 0.53420195, 0.47928994, 0.47727273],\n",
       "       [0.18181818, 0.6875    , 0.1875    , 0.65      , 0.63126492,\n",
       "        0.38356164, 0.21172638, 0.13609467, 0.02272727],\n",
       "       [0.19191919, 0.5       , 0.        , 0.29166667, 0.21718377,\n",
       "        0.38356164, 0.14006515, 0.31952663, 0.11363636],\n",
       "       [0.2020202 , 0.4375    , 0.1875    , 0.28333333, 0.18973747,\n",
       "        0.52054795, 0.28990228, 0.36686391, 0.34090909],\n",
       "       [0.21212121, 0.5       , 0.8125    , 0.06666667, 0.04295943,\n",
       "        0.43835616, 0.08794788, 0.27810651, 0.36363636],\n",
       "       [0.22222222, 0.6875    , 1.        , 0.425     , 0.29952267,\n",
       "        0.50684932, 0.5732899 , 0.69230769, 0.38636364],\n",
       "       [0.23232323, 0.625     , 0.0625    , 0.70833333, 0.71718377,\n",
       "        0.32876712, 0.20846906, 0.24852071, 0.        ],\n",
       "       [0.24242424, 0.        , 0.125     , 0.48333333, 0.41945107,\n",
       "        0.57534247, 0.35179153, 0.38461538, 0.22727273],\n",
       "       [0.25252525, 0.625     , 1.        , 0.53333333, 0.42422434,\n",
       "        0.67123288, 0.61889251, 1.        , 0.47727273],\n",
       "       [0.26262626, 0.0625    , 0.8125    , 0.375     , 0.26431981,\n",
       "        0.47945205, 0.48534202, 0.53254438, 0.36363636],\n",
       "       [0.27272727, 0.4375    , 0.8125    , 0.58333333, 0.53221957,\n",
       "        0.32876712, 0.2247557 , 0.20710059, 0.09090909],\n",
       "       [0.28282828, 0.375     , 0.25      , 0.41666667, 0.31622912,\n",
       "        0.52054795, 0.42996743, 0.34319527, 0.27272727],\n",
       "       [0.29292929, 0.125     , 0.3125    , 0.525     , 0.44928401,\n",
       "        0.38356164, 0.25407166, 0.23076923, 0.18181818],\n",
       "       [0.3030303 , 0.125     , 0.6875    , 0.60833333, 0.52863962,\n",
       "        0.49315068, 0.49185668, 0.49112426, 0.20454545],\n",
       "       [0.31313131, 0.875     , 0.9375    , 0.21666667, 0.14260143,\n",
       "        0.56164384, 0.3713355 , 0.56213018, 0.56818182],\n",
       "       [0.32323232, 0.6875    , 0.4375    , 0.50833333, 0.41587112,\n",
       "        0.68493151, 0.36482085, 0.53254438, 0.25      ],\n",
       "       [0.33333333, 0.125     , 0.625     , 0.63333333, 0.57279236,\n",
       "        0.32876712, 0.43648208, 0.29585799, 0.22727273],\n",
       "       [0.34343434, 0.4375    , 0.75      , 0.45833333, 0.36097852,\n",
       "        0.46575342, 0.38436482, 0.38461538, 0.27272727],\n",
       "       [0.35353535, 0.0625    , 0.125     , 0.48333333, 0.39856802,\n",
       "        0.35616438, 0.31270358, 0.32544379, 0.09090909],\n",
       "       [0.36363636, 0.5625    , 0.0625    , 0.35      , 0.2571599 ,\n",
       "        0.38356164, 0.23452769, 0.31952663, 0.18181818],\n",
       "       [0.37373737, 0.75      , 0.        , 0.25833333, 0.19212411,\n",
       "        0.2739726 , 0.        , 0.07100592, 0.13636364],\n",
       "       [0.38383838, 0.125     , 0.25      , 0.36666667, 0.29653938,\n",
       "        0.32876712, 0.04234528, 0.13017751, 0.04545455],\n",
       "       [0.39393939, 0.0625    , 0.1875    , 0.3       , 0.21300716,\n",
       "        0.43835616, 0.28664495, 0.21893491, 0.25      ],\n",
       "       [0.4040404 , 0.9375    , 0.3125    , 0.28333333, 0.21539379,\n",
       "        0.16438356, 0.07166124, 0.25443787, 0.06818182],\n",
       "       [0.41414141, 0.625     , 1.        , 0.16666667, 0.10083532,\n",
       "        0.7260274 , 0.27361564, 0.32544379, 0.36363636],\n",
       "       [0.42424242, 0.125     , 0.        , 0.63333333, 0.53818616,\n",
       "        0.28767123, 0.58957655, 0.56804734, 0.22727273],\n",
       "       [0.43434343, 0.375     , 0.625     , 0.29166667, 0.20465394,\n",
       "        0.46575342, 0.34527687, 0.36686391, 0.34090909],\n",
       "       [0.44444444, 0.0625    , 0.25      , 0.275     , 0.19689737,\n",
       "        0.36986301, 0.21824104, 0.23668639, 0.20454545],\n",
       "       [0.45454545, 0.5625    , 0.        , 0.6       , 0.52147971,\n",
       "        0.54794521, 0.4267101 , 0.33136095, 0.15909091],\n",
       "       [0.46464646, 0.8125    , 0.0625    , 0.        , 0.        ,\n",
       "        0.21917808, 0.06840391, 0.24852071, 0.27272727],\n",
       "       [0.47474747, 0.6875    , 0.1875    , 0.28333333, 0.19868735,\n",
       "        0.63013699, 0.27687296, 0.46153846, 0.34090909],\n",
       "       [0.48484848, 0.6875    , 0.625     , 0.21666667, 0.1473747 ,\n",
       "        0.45205479, 0.17263844, 0.19526627, 0.15909091],\n",
       "       [0.49494949, 1.        , 0.        , 0.29166667, 0.21420048,\n",
       "        0.24657534, 0.12703583, 0.27218935, 0.09090909],\n",
       "       [0.50505051, 0.625     , 0.875     , 0.19166667, 0.13484487,\n",
       "        0.21917808, 0.03908795, 0.0887574 , 0.13636364],\n",
       "       [0.51515152, 0.625     , 0.6875    , 0.29166667, 0.22076372,\n",
       "        0.09589041, 0.07491857, 0.        , 0.15909091],\n",
       "       [0.52525253, 1.        , 0.25      , 0.2       , 0.14081146,\n",
       "        0.17808219, 0.03257329, 0.30769231, 0.18181818],\n",
       "       [0.53535354, 0.3125    , 0.9375    , 0.56666667, 0.49582339,\n",
       "        0.61643836, 0.36156352, 0.43786982, 0.22727273],\n",
       "       [0.54545455, 0.5625    , 0.875     , 0.375     , 0.3048926 ,\n",
       "        0.28767123, 0.10749186, 0.15976331, 0.09090909],\n",
       "       [0.55555556, 0.5625    , 0.125     , 0.175     , 0.12350835,\n",
       "        0.34246575, 0.05537459, 0.33727811, 0.13636364],\n",
       "       [0.56565657, 0.0625    , 0.5       , 0.61666667, 0.56682578,\n",
       "        0.47945205, 0.28990228, 0.33727811, 0.15909091],\n",
       "       [0.57575758, 0.5       , 0.5625    , 0.36666667, 0.27147971,\n",
       "        0.60273973, 0.32247557, 0.40236686, 0.34090909],\n",
       "       [0.58585859, 0.8125    , 0.25      , 0.25833333, 0.19391408,\n",
       "        0.15068493, 0.        , 0.27810651, 0.04545455],\n",
       "       [0.5959596 , 0.875     , 0.9375    , 0.01666667, 0.01372315,\n",
       "        0.38356164, 0.04885993, 0.19526627, 0.43181818],\n",
       "       [0.60606061, 0.375     , 0.4375    , 0.10833333, 0.06563246,\n",
       "        0.5890411 , 0.14006515, 0.82248521, 0.38636364],\n",
       "       [0.61616162, 1.        , 0.25      , 0.025     , 0.01193317,\n",
       "        0.73972603, 0.16938111, 0.28402367, 0.34090909],\n",
       "       [0.62626263, 0.1875    , 0.6875    , 0.36666667, 0.26491647,\n",
       "        0.47945205, 0.53094463, 0.35502959, 0.45454545],\n",
       "       [0.63636364, 0.9375    , 0.375     , 0.05833333, 0.03520286,\n",
       "        0.09589041, 0.16286645, 0.58579882, 0.38636364],\n",
       "       [0.64646465, 0.4375    , 0.5       , 0.25833333, 0.17720764,\n",
       "        0.57534247, 0.28664495, 0.33136095, 0.29545455],\n",
       "       [0.65656566, 0.125     , 0.625     , 0.375     , 0.27804296,\n",
       "        0.64383562, 0.35830619, 0.35502959, 0.31818182],\n",
       "       [0.66666667, 0.1875    , 0.125     , 0.06666667, 0.03997613,\n",
       "        0.46575342, 0.13029316, 0.21893491, 0.36363636],\n",
       "       [0.67676768, 0.5625    , 0.0625    , 0.16666667, 0.11455847,\n",
       "        0.15068493, 0.02931596, 0.10059172, 0.09090909],\n",
       "       [0.68686869, 0.4375    , 0.375     , 0.05833333, 0.02923628,\n",
       "        0.50684932, 0.33550489, 0.44970414, 0.61363636],\n",
       "       [0.6969697 , 0.5       , 0.625     , 0.24166667, 0.17959427,\n",
       "        0.38356164, 0.04560261, 0.14201183, 0.09090909],\n",
       "       [0.70707071, 0.75      , 0.4375    , 0.6       , 0.55369928,\n",
       "        0.2739726 , 0.21172638, 0.13609467, 0.04545455],\n",
       "       [0.71717172, 0.        , 0.9375    , 0.05833333, 0.02505967,\n",
       "        0.38356164, 0.37459283, 0.32544379, 0.84090909],\n",
       "       [0.72727273, 0.75      , 0.0625    , 0.51666667, 0.43377088,\n",
       "        0.50684932, 0.4723127 , 0.34319527, 0.27272727],\n",
       "       [0.73737374, 0.8125    , 0.875     , 0.31666667, 0.22792363,\n",
       "        0.42465753, 0.29315961, 0.18343195, 0.29545455],\n",
       "       [0.74747475, 0.5625    , 0.125     , 0.225     , 0.16050119,\n",
       "        0.30136986, 0.09771987, 0.21893491, 0.13636364],\n",
       "       [0.75757576, 0.75      , 0.4375    , 0.43333333, 0.36754177,\n",
       "        0.30136986, 0.14983713, 0.26627219, 0.02272727],\n",
       "       [0.76767677, 0.0625    , 0.375     , 0.3       , 0.21300716,\n",
       "        0.80821918, 0.21824104, 0.62130178, 0.29545455],\n",
       "       [0.77777778, 0.125     , 0.625     , 0.56666667, 0.4797136 ,\n",
       "        0.50684932, 0.57654723, 0.47337278, 0.31818182],\n",
       "       [0.78787879, 0.4375    , 0.4375    , 0.76666667, 0.62231504,\n",
       "        0.80821918, 1.        , 0.92307692, 0.63636364],\n",
       "       [0.7979798 , 0.8125    , 0.3125    , 0.25833333, 0.18138425,\n",
       "        0.39726027, 0.18566775, 0.21893491, 0.15909091],\n",
       "       [0.80808081, 0.0625    , 0.4375    , 0.18333333, 0.11933174,\n",
       "        0.54794521, 0.18241042, 0.28994083, 0.38636364],\n",
       "       [0.81818182, 0.5       , 0.625     , 0.28333333, 0.18973747,\n",
       "        0.52054795, 0.37785016, 0.34911243, 0.36363636],\n",
       "       [0.82828283, 0.0625    , 0.25      , 1.        , 1.        ,\n",
       "        0.49315068, 0.74592834, 0.28402367, 0.34090909],\n",
       "       [0.83838384, 0.6875    , 0.1875    , 0.64166667, 0.5548926 ,\n",
       "        0.71232877, 0.45928339, 0.16568047, 0.43181818],\n",
       "       [0.84848485, 1.        , 0.625     , 0.20833333, 0.14379475,\n",
       "        0.36986301, 0.11074919, 0.43195266, 0.15909091],\n",
       "       [0.85858586, 0.3125    , 0.125     , 0.575     , 0.52088305,\n",
       "        0.39726027, 0.21824104, 0.46153846, 0.15909091],\n",
       "       [0.86868687, 0.625     , 0.9375    , 0.35      , 0.26610979,\n",
       "        0.32876712, 0.19869707, 0.43195266, 0.06818182],\n",
       "       [0.87878788, 0.625     , 0.        , 0.58333333, 0.52147971,\n",
       "        0.2739726 , 0.27035831, 0.35502959, 0.06818182],\n",
       "       [0.88888889, 0.125     , 0.        , 0.23333333, 0.1575179 ,\n",
       "        0.24657534, 0.18241042, 0.34319527, 0.25      ],\n",
       "       [0.8989899 , 0.1875    , 0.75      , 0.36666667, 0.26849642,\n",
       "        0.5890411 , 0.31270358, 0.4556213 , 0.22727273],\n",
       "       [0.90909091, 0.875     , 1.        , 0.35833333, 0.27505967,\n",
       "        0.2739726 , 0.15635179, 0.20118343, 0.13636364],\n",
       "       [0.91919192, 0.0625    , 0.0625    , 0.4       , 0.31384248,\n",
       "        0.30136986, 0.21498371, 0.21893491, 0.18181818],\n",
       "       [0.92929293, 0.3125    , 0.1875    , 0.275     , 0.20883055,\n",
       "        0.05479452, 0.04234528, 0.02366864, 0.        ],\n",
       "       [0.93939394, 0.0625    , 0.375     , 0.29166667, 0.21062053,\n",
       "        0.43835616, 0.14332248, 0.17159763, 0.09090909],\n",
       "       [0.94949495, 0.8125    , 0.9375    , 0.4       , 0.30071599,\n",
       "        0.46575342, 0.38110749, 0.30177515, 0.22727273],\n",
       "       [0.95959596, 0.875     , 0.3125    , 0.66666667, 0.63365155,\n",
       "        0.28767123, 0.3029316 , 0.44378698, 0.06818182],\n",
       "       [0.96969697, 0.8125    , 0.1875    , 0.21666667, 0.14856802,\n",
       "        0.47945205, 0.10749186, 0.32544379, 0.29545455],\n",
       "       [0.97979798, 0.625     , 1.        , 0.08333333, 0.05548926,\n",
       "        0.43835616, 0.04885993, 0.        , 0.36363636],\n",
       "       [0.98989899, 0.75      , 0.8125    , 0.18333333, 0.12589499,\n",
       "        0.2739726 , 0.12052117, 0.15976331, 0.29545455],\n",
       "       [1.        , 0.4375    , 1.        , 0.35      , 0.26312649,\n",
       "        0.38356164, 0.247557  , 0.31360947, 0.25      ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "method_names=[] \n",
    "method_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55555556, 0.5625    , 0.125     , 0.175     , 0.12350835,\n",
       "        0.34246575, 0.05537459, 0.33727811, 0.13636364],\n",
       "       [0.88888889, 0.125     , 0.        , 0.23333333, 0.1575179 ,\n",
       "        0.24657534, 0.18241042, 0.34319527, 0.25      ],\n",
       "       [0.26262626, 0.0625    , 0.8125    , 0.375     , 0.26431981,\n",
       "        0.47945205, 0.48534202, 0.53254438, 0.36363636],\n",
       "       [0.42424242, 0.125     , 0.        , 0.63333333, 0.53818616,\n",
       "        0.28767123, 0.58957655, 0.56804734, 0.22727273],\n",
       "       [0.6969697 , 0.5       , 0.625     , 0.24166667, 0.17959427,\n",
       "        0.38356164, 0.04560261, 0.14201183, 0.09090909],\n",
       "       [0.15151515, 0.8125    , 0.5       , 0.375     , 0.27267303,\n",
       "        0.60273973, 0.39739414, 0.56213018, 0.40909091],\n",
       "       [0.4040404 , 0.9375    , 0.3125    , 0.28333333, 0.21539379,\n",
       "        0.16438356, 0.07166124, 0.25443787, 0.06818182],\n",
       "       [0.96969697, 0.8125    , 0.1875    , 0.21666667, 0.14856802,\n",
       "        0.47945205, 0.10749186, 0.32544379, 0.29545455],\n",
       "       [0.09090909, 1.        , 0.        , 0.26666667, 0.16348449,\n",
       "        0.67123288, 0.65798046, 0.40236686, 0.65909091],\n",
       "       [0.72727273, 0.75      , 0.0625    , 0.51666667, 0.43377088,\n",
       "        0.50684932, 0.4723127 , 0.34319527, 0.27272727],\n",
       "       [0.11111111, 0.5       , 0.25      , 0.43333333, 0.34546539,\n",
       "        0.36986301, 0.29641694, 0.28994083, 0.18181818],\n",
       "       [0.47474747, 0.6875    , 0.1875    , 0.28333333, 0.19868735,\n",
       "        0.63013699, 0.27687296, 0.46153846, 0.34090909],\n",
       "       [0.85858586, 0.3125    , 0.125     , 0.575     , 0.52088305,\n",
       "        0.39726027, 0.21824104, 0.46153846, 0.15909091],\n",
       "       [0.28282828, 0.375     , 0.25      , 0.41666667, 0.31622912,\n",
       "        0.52054795, 0.42996743, 0.34319527, 0.27272727],\n",
       "       [0.93939394, 0.0625    , 0.375     , 0.29166667, 0.21062053,\n",
       "        0.43835616, 0.14332248, 0.17159763, 0.09090909],\n",
       "       [0.05050505, 1.        , 0.875     , 0.25833333, 0.16408115,\n",
       "        0.79452055, 0.42996743, 0.43786982, 0.52272727],\n",
       "       [0.66666667, 0.1875    , 0.125     , 0.06666667, 0.03997613,\n",
       "        0.46575342, 0.13029316, 0.21893491, 0.36363636],\n",
       "       [0.65656566, 0.125     , 0.625     , 0.375     , 0.27804296,\n",
       "        0.64383562, 0.35830619, 0.35502959, 0.31818182],\n",
       "       [0.35353535, 0.0625    , 0.125     , 0.48333333, 0.39856802,\n",
       "        0.35616438, 0.31270358, 0.32544379, 0.09090909],\n",
       "       [0.16161616, 0.0625    , 0.3125    , 0.35833333, 0.28818616,\n",
       "        0.39726027, 0.11074919, 0.14201183, 0.13636364],\n",
       "       [0.49494949, 1.        , 0.        , 0.29166667, 0.21420048,\n",
       "        0.24657534, 0.12703583, 0.27218935, 0.09090909],\n",
       "       [0.34343434, 0.4375    , 0.75      , 0.45833333, 0.36097852,\n",
       "        0.46575342, 0.38436482, 0.38461538, 0.27272727],\n",
       "       [0.07070707, 0.375     , 0.4375    , 0.31666667, 0.22434368,\n",
       "        0.67123288, 0.41368078, 0.50295858, 0.5       ],\n",
       "       [0.95959596, 0.875     , 0.3125    , 0.66666667, 0.63365155,\n",
       "        0.28767123, 0.3029316 , 0.44378698, 0.06818182],\n",
       "       [0.27272727, 0.4375    , 0.8125    , 0.58333333, 0.53221957,\n",
       "        0.32876712, 0.2247557 , 0.20710059, 0.09090909],\n",
       "       [0.19191919, 0.5       , 0.        , 0.29166667, 0.21718377,\n",
       "        0.38356164, 0.14006515, 0.31952663, 0.11363636],\n",
       "       [0.81818182, 0.5       , 0.625     , 0.28333333, 0.18973747,\n",
       "        0.52054795, 0.37785016, 0.34911243, 0.36363636],\n",
       "       [0.25252525, 0.625     , 1.        , 0.53333333, 0.42422434,\n",
       "        0.67123288, 0.61889251, 1.        , 0.47727273],\n",
       "       [0.62626263, 0.1875    , 0.6875    , 0.36666667, 0.26491647,\n",
       "        0.47945205, 0.53094463, 0.35502959, 0.45454545],\n",
       "       [0.13131313, 0.1875    , 0.6875    , 0.43333333, 0.34665871,\n",
       "        0.19178082, 0.2019544 , 0.29585799, 0.        ],\n",
       "       [0.24242424, 0.        , 0.125     , 0.48333333, 0.41945107,\n",
       "        0.57534247, 0.35179153, 0.38461538, 0.22727273],\n",
       "       [0.03030303, 0.3125    , 0.3125    , 0.21666667, 0.1097852 ,\n",
       "        0.        , 0.80130293, 0.73964497, 1.        ],\n",
       "       [0.17171717, 0.375     , 0.1875    , 0.46666667, 0.35620525,\n",
       "        0.64383562, 0.53420195, 0.47928994, 0.47727273],\n",
       "       [0.38383838, 0.125     , 0.25      , 0.36666667, 0.29653938,\n",
       "        0.32876712, 0.04234528, 0.13017751, 0.04545455],\n",
       "       [0.08080808, 0.625     , 0.8125    , 0.3       , 0.18973747,\n",
       "        0.78082192, 0.50488599, 0.59171598, 0.47727273],\n",
       "       [0.78787879, 0.4375    , 0.4375    , 0.76666667, 0.62231504,\n",
       "        0.80821918, 1.        , 0.92307692, 0.63636364],\n",
       "       [0.06060606, 0.4375    , 0.9375    , 0.56666667, 0.5       ,\n",
       "        0.34246575, 0.23127036, 0.26035503, 0.09090909],\n",
       "       [0.64646465, 0.4375    , 0.5       , 0.25833333, 0.17720764,\n",
       "        0.57534247, 0.28664495, 0.33136095, 0.29545455],\n",
       "       [0.36363636, 0.5625    , 0.0625    , 0.35      , 0.2571599 ,\n",
       "        0.38356164, 0.23452769, 0.31952663, 0.18181818],\n",
       "       [0.8989899 , 0.1875    , 0.75      , 0.36666667, 0.26849642,\n",
       "        0.5890411 , 0.31270358, 0.4556213 , 0.22727273],\n",
       "       [0.56565657, 0.0625    , 0.5       , 0.61666667, 0.56682578,\n",
       "        0.47945205, 0.28990228, 0.33727811, 0.15909091],\n",
       "       [1.        , 0.4375    , 1.        , 0.35      , 0.26312649,\n",
       "        0.38356164, 0.247557  , 0.31360947, 0.25      ],\n",
       "       [0.54545455, 0.5625    , 0.875     , 0.375     , 0.3048926 ,\n",
       "        0.28767123, 0.10749186, 0.15976331, 0.09090909],\n",
       "       [0.43434343, 0.375     , 0.625     , 0.29166667, 0.20465394,\n",
       "        0.46575342, 0.34527687, 0.36686391, 0.34090909],\n",
       "       [0.50505051, 0.625     , 0.875     , 0.19166667, 0.13484487,\n",
       "        0.21917808, 0.03908795, 0.0887574 , 0.13636364],\n",
       "       [0.67676768, 0.5625    , 0.0625    , 0.16666667, 0.11455847,\n",
       "        0.15068493, 0.02931596, 0.10059172, 0.09090909],\n",
       "       [0.46464646, 0.8125    , 0.0625    , 0.        , 0.        ,\n",
       "        0.21917808, 0.06840391, 0.24852071, 0.27272727],\n",
       "       [0.68686869, 0.4375    , 0.375     , 0.05833333, 0.02923628,\n",
       "        0.50684932, 0.33550489, 0.44970414, 0.61363636],\n",
       "       [0.61616162, 1.        , 0.25      , 0.025     , 0.01193317,\n",
       "        0.73972603, 0.16938111, 0.28402367, 0.34090909],\n",
       "       [0.97979798, 0.625     , 1.        , 0.08333333, 0.05548926,\n",
       "        0.43835616, 0.04885993, 0.        , 0.36363636],\n",
       "       [0.7979798 , 0.8125    , 0.3125    , 0.25833333, 0.18138425,\n",
       "        0.39726027, 0.18566775, 0.21893491, 0.15909091],\n",
       "       [0.41414141, 0.625     , 1.        , 0.16666667, 0.10083532,\n",
       "        0.7260274 , 0.27361564, 0.32544379, 0.36363636],\n",
       "       [0.58585859, 0.8125    , 0.25      , 0.25833333, 0.19391408,\n",
       "        0.15068493, 0.        , 0.27810651, 0.04545455],\n",
       "       [0.48484848, 0.6875    , 0.625     , 0.21666667, 0.1473747 ,\n",
       "        0.45205479, 0.17263844, 0.19526627, 0.15909091],\n",
       "       [0.98989899, 0.75      , 0.8125    , 0.18333333, 0.12589499,\n",
       "        0.2739726 , 0.12052117, 0.15976331, 0.29545455],\n",
       "       [0.57575758, 0.5       , 0.5625    , 0.36666667, 0.27147971,\n",
       "        0.60273973, 0.32247557, 0.40236686, 0.34090909],\n",
       "       [0.75757576, 0.75      , 0.4375    , 0.43333333, 0.36754177,\n",
       "        0.30136986, 0.14983713, 0.26627219, 0.02272727],\n",
       "       [0.32323232, 0.6875    , 0.4375    , 0.50833333, 0.41587112,\n",
       "        0.68493151, 0.36482085, 0.53254438, 0.25      ],\n",
       "       [0.94949495, 0.8125    , 0.9375    , 0.4       , 0.30071599,\n",
       "        0.46575342, 0.38110749, 0.30177515, 0.22727273],\n",
       "       [0.5959596 , 0.875     , 0.9375    , 0.01666667, 0.01372315,\n",
       "        0.38356164, 0.04885993, 0.19526627, 0.43181818],\n",
       "       [0.63636364, 0.9375    , 0.375     , 0.05833333, 0.03520286,\n",
       "        0.09589041, 0.16286645, 0.58579882, 0.38636364],\n",
       "       [0.84848485, 1.        , 0.625     , 0.20833333, 0.14379475,\n",
       "        0.36986301, 0.11074919, 0.43195266, 0.15909091],\n",
       "       [0.37373737, 0.75      , 0.        , 0.25833333, 0.19212411,\n",
       "        0.2739726 , 0.        , 0.07100592, 0.13636364],\n",
       "       [0.29292929, 0.125     , 0.3125    , 0.525     , 0.44928401,\n",
       "        0.38356164, 0.25407166, 0.23076923, 0.18181818],\n",
       "       [0.01010101, 0.        , 0.125     , 0.675     , 0.67064439,\n",
       "        1.        , 0.13355049, 0.27218935, 0.09090909],\n",
       "       [0.52525253, 1.        , 0.25      , 0.2       , 0.14081146,\n",
       "        0.17808219, 0.03257329, 0.30769231, 0.18181818],\n",
       "       [0.21212121, 0.5       , 0.8125    , 0.06666667, 0.04295943,\n",
       "        0.43835616, 0.08794788, 0.27810651, 0.36363636],\n",
       "       [0.02020202, 0.75      , 1.        , 0.65      , 0.59725537,\n",
       "        0.75342466, 0.39739414, 0.4260355 , 0.15909091],\n",
       "       [0.23232323, 0.625     , 0.0625    , 0.70833333, 0.71718377,\n",
       "        0.32876712, 0.20846906, 0.24852071, 0.        ],\n",
       "       [0.87878788, 0.625     , 0.        , 0.58333333, 0.52147971,\n",
       "        0.2739726 , 0.27035831, 0.35502959, 0.06818182],\n",
       "       [0.91919192, 0.0625    , 0.0625    , 0.4       , 0.31384248,\n",
       "        0.30136986, 0.21498371, 0.21893491, 0.18181818],\n",
       "       [0.74747475, 0.5625    , 0.125     , 0.225     , 0.16050119,\n",
       "        0.30136986, 0.09771987, 0.21893491, 0.13636364],\n",
       "       [0.86868687, 0.625     , 0.9375    , 0.35      , 0.26610979,\n",
       "        0.32876712, 0.19869707, 0.43195266, 0.06818182],\n",
       "       [0.82828283, 0.0625    , 0.25      , 1.        , 1.        ,\n",
       "        0.49315068, 0.74592834, 0.28402367, 0.34090909],\n",
       "       [0.2020202 , 0.4375    , 0.1875    , 0.28333333, 0.18973747,\n",
       "        0.52054795, 0.28990228, 0.36686391, 0.34090909],\n",
       "       [0.60606061, 0.375     , 0.4375    , 0.10833333, 0.06563246,\n",
       "        0.5890411 , 0.14006515, 0.82248521, 0.38636364],\n",
       "       [0.71717172, 0.        , 0.9375    , 0.05833333, 0.02505967,\n",
       "        0.38356164, 0.37459283, 0.32544379, 0.84090909],\n",
       "       [0.14141414, 0.1875    , 0.125     , 0.35      , 0.22434368,\n",
       "        0.5890411 , 0.62214984, 0.4260355 , 0.54545455],\n",
       "       [0.92929293, 0.3125    , 0.1875    , 0.275     , 0.20883055,\n",
       "        0.05479452, 0.04234528, 0.02366864, 0.        ],\n",
       "       [0.51515152, 0.625     , 0.6875    , 0.29166667, 0.22076372,\n",
       "        0.09589041, 0.07491857, 0.        , 0.15909091]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Logistic Regression <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Test Accuracy 0.85\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train) #Fitting\n",
    "print(\"Logistic Regression Classification Test Accuracy {}\".format(log_reg.score(x_test,y_test)))\n",
    "method_names.append(\"Logistic Reg.\")\n",
    "method_scores.append(log_reg.score(x_test,y_test))\n",
    "\n",
    "#Confusion Matrix\n",
    "y_pred = log_reg.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "#Visualization Confusion Matrix\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Support Vector Machine <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Score is: 0.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(x_train,y_train)\n",
    "print(\"SVM Classification Score is: {}\".format(svm.score(x_test,y_test)))\n",
    "method_names.append(\"SVM\")\n",
    "method_scores.append(svm.score(x_test,y_test))\n",
    "\n",
    "\n",
    "y_pred = svm.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Decision Tree<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Score:  0.7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(x_train,y_train)\n",
    "print(\"Decision Tree Classification Score: \",dec_tree.score(x_test,y_test))\n",
    "method_names.append(\"Decision Tree\")\n",
    "method_scores.append(dec_tree.score(x_test,y_test))\n",
    "\n",
    "\n",
    "y_pred = dec_tree.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random Forest<b>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Score:  0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAFBCAYAAAAIZQhgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXKklEQVR4nO3dedQkZXX48e+dBZFNQZbgIAEUIYAK/AZEOSCERRQOYIgGDhAUZDBGjfJLFEVDyOJJgqJw3HgFBJQMyqYQjKDIpgKCrCMTBWGEYZEhQEQWmeG9+aNr4HV4l+6aqu7qqe/HU4fu6u6n7jCH632WeioyE0la0U0bdACS1A8mO0mtYLKT1AomO0mtYLKT1AomO0mtYLKT1GgRcXpEPBwR88b57G8jIiNi7anaMdlJarozgL2WPRkRrwL2AO7tphGTnaRGy8yrgUfH+ehzwEeBru6MMNlJGjoRsS9wf2be2u1vZtQYz/KJ8D42aRAyo8zPFj9yd6n/Zlda59VHAXPGnBrJzJGJvh8RqwDHAnv2cp3mJjtgxsxXDjoElbBk8QMA7PjKXQccicr4cZ+vVyS2CZPbOF4NbAzcGhEAGwA3RcT2mfnQRD9qdLKTNERGn+vLZTLzdmDdpe8jYgEwOzMfmex3jtlJqkaOljumEBFzgWuBzSJiYUQcUSY8KztJ1RidOnGVkZkHTfH5Rt20Y7KTVInsokobJJOdpGrUVNlVxWQnqRpWdpJaoU+zsWWZ7CRVw8pOUis4ZiepDZyNldQOVnaSWsHKTlIrOBsrqRWs7CS1gmN2klqh4ZWdWzxJagUrO0nVsBsrqQ0ynY2V1AYNH7Mz2Umqht1YSa1gZSepFbyDQlIrWNlJagXH7CS1gpWdpFawspPUCiY7SW3gHRSS2sHKTlIrOEEhqRWs7CS1QsMrOzfvlNQKVnaSqmE3VlIr2I2V1Aqjo+WOKUTE6RHxcETMG3PuhIj474i4LSIujIiXT9WOyU5SNWpKdsAZwF7LnPs+sFVmvh74JfDxqRox2UmqRo6WO6ZqNvNq4NFlzl2WmUuKt9cBG0zVjmN2kqoxuAmKw4FvTvUlKztJ1ShZ2UXEnIi4ccwxp9tLRsSxwBLg7Km+a2UnqRolK7vMHAFGev1dRBwG7APslpk51fdNdpKq0celJxGxF/Ax4C2Z+VQ3vzHZSapGTWN2ETEX2AVYOyIWAsfRmX19CfD9iAC4LjPfN1k7JjtJ1agp2WXmQeOcPq3Xdkx2kqox9bDZQJnsJFXDe2MltYLJTlIrNHwjAJOdpGo0vLLzDgpJrWBlJ6kazsZKaoWGd2NNdpKqYbKT1ArOxkpqgxx1zE5SG9iNldQKdmMltYLdWEmtYDdWUiuY7DTWV0c+y95v352HFz3C1tvsNuhw1IOVXjKTL55/EjNfMpMZ06dzxSVXcdpnzxx0WM3R8DsovDe2z84661vsvc/Bgw5DJTz7+8V86F1H8+49juSwPY/kjbtsz5bb/smgw2qO+h6SXQmTXZ9d86PrefSxxwcdhkp6+qlnAJgxYwYzZs6gi4datcdoljv6pLZubERsDuwHzAISeAC4KDPn13VNqW7Tpk3j9O99hVkbzeKCM77NHTf/96BDao6GLz2ppbKLiI8B5wAB/BS4oXg9NyKOqeOaUj+Mjo7y7j3n8I7Z72KLbTZn4802GnRIzdHSyu4IYMvMXDz2ZEScCPwc+NfxflQ8CXwOwCk1BSZV4Xe/fZKbfnIrO+yyPff8YsGgw2mEbPhsbF1jdqPAK8c5v37x2bgycyQzZ2fm7Dk1BSaV9fK1XsZqa6wKwEorr8R2O23Lr39174CjUrfqquw+DFweEXcC9xXnNgReA3ygpmsOhW98/Yu8Zec3sfbaa7Hg7hs5/h8/w9fOOGfQYakLr1jvFXzy8x9j2rRpTJs2jR9efCU/+cF1gw6rOdp4B0Vmfi8iXgtsT2eCIoCFwA2Z+Vwd1xwWhxz614MOQSX9av7dvOetRw06jOZq+ARFbbOxmTkK+H97Ulu0sbKT1EINn6Aw2UmqhpWdpFZo65idpJaxspPUBk1fVGyyk1QNKztJrdDwZOcWT5KqkaPljilExOkR8XBEzBtzbq2I+H5E3Fn8c82p2jHZSapGfbuenAHstcy5Y4DLM3NT4PLi/aRMdpIqkaNZ6piy3cyrgUeXOb0fsHRP/DOB/adqxzE7SdXo75jdepn5IEBmPhgR6071A5OdpGqUXHoydh/LwkhmjlQS0xgmO0nVKFnZFYmt1+T2m4hYv6jq1gcenuoHjtlJqkZ/t2W/CDiseH0Y8J2pfmCyk9RoETEXuBbYLCIWRsQRdB7tsEexQfAeTPCoh7HsxkqqRF2PlczMgyb4qKenzJvsJFWj4XdQmOwkVcNkJ6kNulkgPEgmO0nVMNlJaoVmb2dnspNUDbuxktrBZCepFezGSmoDu7GS2sHKTlIbWNlJagcrO0lt0MWzcwbKZCepGiY7SW3Q9MrOzTsltYKVnaRqNLyyM9lJqkTTu7EmO0mVMNlJaoWmJ7spJygiYseIWLV4fUhEnBgRf1x/aJKGSka5o0+6mY39MvBURLwB+Cjwa+CsWqOSNHRytNzRL90kuyXZeUbafsBJmXkSsHq9YUkaNjkapY5+6WbM7omI+DhwKLBTREwHZtYblqRhM/RjdsBfAL8HDs/Mh4BZwAm1RiVp6GRGqaNfpqzsMvOhiDgf2LQ49QhwYa1RSRo6Q1/ZRcSRwHnAKcWpWcC3a4xJ0hBq+phdN93YvwZ2BH4LkJl3AuvWGZSk4ZNZ7uiXbiYofp+Zz0Z0MnBEzACavSWppL7rZ5VWRjfJ7qqI+ATw0ojYA3g/cHG9YUkaNk1Pdt10Y48BFgG3A0cB3wU+WWdQkobP0HdjM3MU+GpxSNK4ml7ZTZnsIuIexhmjy8xNaolIkmrQzZjd7DGvVwbeCaxVTziShlWdC4Qj4iPAe+kUXrcD78nMZ3ppY8oxu8z8nzHH/Zn5eeBPywQsacVV10YAETEL+BAwOzO3AqYDB/YaXzfd2G3HvJ1Gp9JzIwBJf2C03lu/ZtBZEbIYWAV4oEwDU/nsmNdLgAXAu3q9kKQVW9lubETMAeaMOTWSmSMvtJv3R8RngHuBp4HLMvOyXq/TzWzsrr02Kql9ys7GFoltZKLPI2JNOlvMbQw8DpwbEYdk5jd6uc6EyS4ijp4iwBN7uZCkFVuNa+Z2B+7JzEUAEXEB8GagmmSH43KSelDjOrt7gR0iYhU63djdgBt7bWTCZJeZx5ePTVLb1DVBkZnXR8R5wE105g1uZpJu70S6mY1dGTgC2JLOOrulARze68UkrbjqXGeXmccBxy1PG93cG/t14I+AtwJXARsATyzPRSWteJp+b2w3ye41mfkp4MnMPBPYG3hdvWFJGjajGaWOfulmnd3i4p+PR8RWwEPARrVFJGko9fN5EmV0k+xGinUunwIuAlYrXkvS8/rZJS1jsnV2dwBnA+dk5mN0xuv6utPJksU93xGiBvnxA1cMOgT1UT+7pGVMNmZ3EJ0q7rKIuD4iPhwR6/cpLklDZmgfpZiZtwK3Ah+PiB3oPD/2+oi4C5ibmbVv5rnhmlvVfQnV4N7H5gGweNGvBhyJyphZ8nfDXNk9LzOvy8yPAH8JrAl8odaoJKli3Swq3o5Ol/YAOjuejADn1huWpGHT8PmJSScoPk2n6/oYcA6wY2Yu7FdgkoZL07uxk1V2vwfelpm/7FcwkobX0K6zcyMASb3oYof1gepmUbEkTSkZ0spOknox2vAZiimXnkTHIRHx98X7DSNi+/pDkzRMRolSR790s87uS8Cb6Cw/gc72Tl+sLSJJQymJUke/dNONfWNmbhsRNwNk5mMRsVLNcUkaMivCBMXiiJhOsWYwItah+X8uSX3W9AmKbrqxJwMXAutGxL8APwI+XWtUkobOaMmjX7p5buzZEfEzOk/0CWD/zJxfe2SShkrTu3vd3Bu7IfAUcPHYc5l5b52BSRouTe/GdjNmdwmd8bqg83SxjYFf0HnamCQBUN9jY6vRTTf2Dx6uExHbAkfVFpGkodTPNXNl9HwHRWbeVGz7JEnPa/gNFF2N2R095u00YFtgUW0RSVINuqnsVh/zegmdMbzz6wlH0rAa6tnYYjHxapn5d32KR9KQGo0hHbOLiBmZuaSYkJCkSQ3zmN1P6YzP3RIRF9F57sSTSz/MzAtqjk3SEBnqbmxhLeB/gD/lhfV2CZjsJD1vmNfZrVvMxM7jhSS3VNMrVkl9Nszr7KYDq8G4fwKTnaQ/0PSkMFmyezAz/7FvkUgaanV2YyPi5cCpwFZ08urhmXltL21MluyaXZNKapSaJyhOAr6XmX9ebB68Sq8NTJbsdisdlqTWqasbGxFrADsD7wbIzGeBZ3ttZ8LNOzPz0bLBSWqf0Sh3dGETOreofi0ibo6IUyNi1V7j62anYkmaUtmdiiNiTkTcOOaYs0zTM+is+f1yZm5DZ73vMb3G53NjJVWi7JhdZo4AI5N8ZSGwMDOvL96fR4lkZ2UnqRIZ5Y4p2818CLgvIjYrTu0G3NFrfFZ2kipR82zsB4Gzi5nYu4H39NqAyU5SJepMdpl5CzB7edow2UmqRNPvoHDMTlIrWNlJqsQw73oiSV1bEfazk6QpmewktULTJyhMdpIq4ZidpFawGyupFezGSmqF0YanO5OdpErYjZXUCs2u60x2kipiZSepFVx6IqkVnKCQ1ArNTnUmO0kVccxOUis0vRvr5p2SWsHKTlIlml3XmewkVcQxO0mt0PQxO5OdpEo0O9WZ7CRVxG6spFbIhtd2JjtJlbCyk9QKTZ+gcFFxn60/az3O+c5pXH7dd/jBTy7k8KMOHnRImsQnP30iO+99IPsf8r4Xffa1/ziPrXZ8G489/r8DiKx5suTRLya7PntuyXP886c+w2477Md+ex7MXx5xIJtutsmgw9IE9n/7HnzlxH9+0fkHf7OIa2+4mfXXW3cAUTXTKFnq6BeTXZ89/JtHmHfbfACe/N1T3PXLe/ij9dcbcFSayOytX8fL1lj9Ref//eRTOPr9RxAN38Otn0ZLHv3S92QXEe/p9zWbaoNXvZItX785N//stkGHoh5ccc11rLvO2my+qRX5WFnyf/0yiMru+AFcs3FWWfWlnHLm5zj+E//G7554ctDhqEtPP/MMI2edwwfee+igQ2mcpld2tczGRsREpUoAE/bZImIOMAfglBriaooZM2Zwypmf48LzLuF7/3n5oMNRD+67/0Huf+AhDjjs/QD8ZtEjvPPwD3LOVz/P2q9Ya8DRDVZb19mtB7wVeGyZ8wH8ZKIfZeYIMNL5ZuSLh4VXDCecfDx3/fJuTv3SWYMORT167as35upLznn+/Z4HHMY3TzuZNV/+sgFG1Qx1VmkRMR24Ebg/M/cp00Zd3dj/BFbLzF8vcywArqzpmkNhuzduwwEH7subd3oj/3XVufzXVeey6+47DTosTeDvjvtXDj7qIyy4dyG77X8I51986aBDaqzRzFJHl/4GmL888UV2f7H+isgN19xq0FGohHsfmwfA4kW/GnAkKmPm2puUmmM+9I//rFQy+fqvL5j0ehGxAXAm8C/A0WUrO++gkFSJGsumzwMfBV68BqgHrrOTVImyi4ojYk5E3DjmmLO0zYjYB3g4M3+2vPFZ2UmqRNnZ2D+YmHyxHYF9I+LtwMrAGhHxjcw8pNfrWNlJqkQd6+wy8+OZuUFmbgQcCPywTKIDKztJFWn6ricmO0mVqHtRcWZeyXIsXTPZSaqEm3dKaoXGrtktmOwkVcIxO0mtYDdWUiu0ddcTSS1jN1ZSKzhBIakVHLOT1AqO2UlqhaaP2bkRgKRWsLKTVAknKCS1QtO7sSY7SZVwgkJSK/TwpLCBMNlJqkSzU53JTlJFHLOT1AomO0mt4NITSa1gZSepFVx6IqkV7MZKagW7sZJawcpOUitY2UlqBScoJLVC0++NdfNOSa1gZSepEnZjJbVC07uxJjtJlbCyk9QKVnaSWqHplZ2zsZIqMZpZ6phKRLwqIq6IiPkR8fOI+Jsy8VnZSapEjZXdEuD/Z+ZNEbE68LOI+H5m3tFLIyY7SZXIHK2p3XwQeLB4/UREzAdmASY7Sf3Xj3tjI2IjYBvg+l5/65idpEpkZqkjIuZExI1jjjnjtR8RqwHnAx/OzN/2Gp+VnaRKlK3sMnMEGJnsOxExk06iOzszLyhzHZOdpErUtZ9dRARwGjA/M08s247JTlIlalxUvCNwKHB7RNxSnPtEZn63l0ZMdpIqUdfSk8z8ERDL247JTlIl3JZdUiu4LbukVmh6Zec6O0mtYGUnqRJu8SSpFZrejTXZSaqEExSSWsHKTlIrOGYnqRWavi27yU5SJazsJLWCY3aSWsFurKRWsLKT1ApNT3bR2AAjGhqYtILLLLV33IyVZpX6b3bJs/cv91513WhuslvBRcScYu99DSH//oaPu54MzrhPUNLQ8O9vyJjsJLWCyU5SK5jsBsfxnuHm39+QcYJCUitY2UlqBZNdn0XEXhHxi4i4KyKOGXQ86k1EnB4RD0fEvEHHot6Y7PooIqYDXwTeBmwBHBQRWww2KvXoDGCvQQeh3pns+mt74K7MvDsznwXOAfYbcEzqQWZeDTw66DjUO5Ndf80C7hvzfmFxTlLNTHb9Nd49gE6HS31gsuuvhcCrxrzfAHhgQLFIrWKy668bgE0jYuOIWAk4ELhowDFJrWCy66PMXAJ8ALgUmA98KzN/Ptio1IuImAtcC2wWEQsj4ohBx6TueAeFpFawspPUCiY7Sa1gspPUCiY7Sa1gspPUCia7IRQRz0XELRExLyLOjYhVlqOtMyLiz4vXp062MUFE7BIRby5xjQURsfY41z1qmXP7R8R3u4lV6pXJbjg9nZlbZ+ZWwLPA+8Z+WOyu0rPMfG9m3jHJV3YBek52E5hLZ1H1WAcW56XKmeyG3zXAa4qq64qI+A/g9oiYHhEnRMQNEXHb0ioqOr4QEXdExCXAuksbiogrI2J28XqviLgpIm6NiMsjYiM6SfUjRVW5U0SsExHnF9e4ISJ2LH77ioi4LCJujohTGP+e4B8Am0fE+sVvVgF2B74dEX9ftDcvIkYi4kW/H1stRsTsiLiyeL1qsefcDcX19yvObxkRPy1ivy0iNq3iX76Gh8luiEXEDDp7491enNoeODYztwCOAP43M7cDtgOOjIiNgXcAmwGvA45knEotItYBvgockJlvAN6ZmQuArwCfK6rKa4CTivfbAQcApxZNHAf8KDO3oXM73IbLXiMznwMuAN5VnNoXuCIznwC+kJnbFZXrS4F9evjXcizwwyKmXYETImJVOon6pMzcGphN5z5ltciMQQegUl4aEbcUr68BTqOTtH6amfcU5/cEXj9mjOtlwKbAzsDcItk8EBE/HKf9HYCrl7aVmRPt37Y7sMWYwmuNiFi9uMafFb+9JCIem+D3c4ET6CTNA4GzivO7RsRHgVWAtYCfAxdP0May9gT2jYi/Ld6vTCfZXgscGxEbABdk5p1dtqcVhMluOD1dVCjPKxLOk2NPAR/MzEuX+d7bmXpbqejiO9DpGbwpM58eJ5Zufv9jYP2IeAOdZH1gRKwMfAmYnZn3RcQ/0ElYy1rCCz2TsZ8HnYr0F8t8f35EXA/sDVwaEe/NzPESvVZQdmNXXJcCfxURMwEi4rVFd+5qOkllejFetus4v70WeEvR7SUi1irOPwGsPuZ7l9HZ2IDie1sXL68GDi7OvQ1Yc7wAs3Nj9reAM4HvZuYzvJC4HomI1YCJZl8XAP+veH3AMn/uDy4d54uIbYp/bgLcnZkn0+lav36CdrWCMtmtuE4F7gBuKh4OcwqdSv5C4E4643xfBq5a9oeZuQiYA1wQEbcC3yw+uhh4x9IJCuBDwOxiwP8OXpgVPh7YOSJuotOtvHeSOOcCb6CzRT2Z+Tid8cLbgW/T2RZrPMcDJ0XENcBzY87/EzATuK34c/9Tcf4vgHlF939zXugyqyXc9URSK1jZSWoFk52kVjDZSWoFk52kVjDZSWoFk52kVjDZSWoFk52kVvg/pgN1G2AFFBgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rand_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rand_forest.fit(x_train,y_train)\n",
    "print(\"Random Forest Classification Score: \",rand_forest.score(x_test,y_test))\n",
    "method_names.append(\"Random Forest\")\n",
    "method_scores.append(rand_forest.score(x_test,y_test))\n",
    "\n",
    "\n",
    "y_pred = rand_forest.predict(x_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5731\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5419\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5627\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5523\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5523\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5314\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5523\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5314\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5627\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5314\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6915 - accuracy: 0.5106\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5523\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5210\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5210\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5523\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5314\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5419\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5210\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5523\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5627\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5314\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5210\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5523\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 965us/step - loss: 0.6816 - accuracy: 0.5314\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5523\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5523\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.6766 - accuracy: 0.5314\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5731\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5523\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.6674 - accuracy: 0.5627\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5523\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5627\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5649\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6562 - accuracy: 0.5879\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6317\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6501 - accuracy: 0.6798\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6737\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6842\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.6374 - accuracy: 0.7510\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.7449\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7761\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.7553\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 967us/step - loss: 0.6200 - accuracy: 0.8013\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.8325\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.8347\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.8265\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5934 - accuracy: 0.8577\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.8473\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.8577\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.8473\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.8473\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.8473\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.8703\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.5462 - accuracy: 0.8599\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8829\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.9163\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.5407 - accuracy: 0.8850\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.9059\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8954\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.5040 - accuracy: 0.9163\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.9163\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.9163\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8954\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.4666 - accuracy: 0.9267\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9059\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.9163\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.4434 - accuracy: 0.9059\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.4465 - accuracy: 0.9059\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.9059\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.4536 - accuracy: 0.9080\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.9184\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.4166 - accuracy: 0.9289\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.9184\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.9184\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3928 - accuracy: 0.9393\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.9184\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.9414\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.9310\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.9310\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.9518\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.9414\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.9310\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.9414\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.9623\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.9310\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3805 - accuracy: 0.9310\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.3482 - accuracy: 0.9518\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.9414\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.9414\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.9310\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.9414\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.9414\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.9623\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.9414\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.9310\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.9414\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.9393\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.9184\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.9393\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.9184\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3308 - accuracy: 0.9184\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.9289\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.9393\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.9393\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.9393\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.9184\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.9184\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9289\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3235 - accuracy: 0.9080\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.9184\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.9184\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9393\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.9184\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9184\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2826 - accuracy: 0.9289\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.9289\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2830 - accuracy: 0.9184\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2934 - accuracy: 0.9184\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.9080\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.9289\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3105 - accuracy: 0.9080\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9080\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9497\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.9080\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9289\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9393\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.9289\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.9184\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9393\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.9289\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9289\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2965 - accuracy: 0.9184\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2649 - accuracy: 0.9289\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9289\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9184\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3037 - accuracy: 0.9080\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2839 - accuracy: 0.9289\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2908 - accuracy: 0.9184\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9289\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2594 - accuracy: 0.9289\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9393\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.2587 - accuracy: 0.9289\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2449 - accuracy: 0.9289\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2581 - accuracy: 0.9289\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2742 - accuracy: 0.9289\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 964us/step - loss: 0.2703 - accuracy: 0.9289\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.9184\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9184\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9393\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9289\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.9184\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9393\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9289\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2620 - accuracy: 0.9184\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9289\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2613 - accuracy: 0.9184\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9080\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9289\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9393\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9184\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9184\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.9184\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.9184\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9184\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2338 - accuracy: 0.9289\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9184\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9080\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9184\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.9184\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2550 - accuracy: 0.9184\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9289\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9289\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2584 - accuracy: 0.9289\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9289\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9414\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9414\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9310\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9414\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9518\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9414\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9518\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9414\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9310\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9518\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9414\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9414\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9414\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9518\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9414\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2209 - accuracy: 0.9414\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9518\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9518\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9623\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9414\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9310\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9184\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9080\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.9289\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9289\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2382 - accuracy: 0.9414\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.3586 - accuracy: 0.7778\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6169\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6590\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6930 - accuracy: 0.5731\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5523\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6928 - accuracy: 0.5210\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5419\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5419\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6922 - accuracy: 0.5523\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5627\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6919 - accuracy: 0.5419\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5627\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5835\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.6913 - accuracy: 0.5314\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.6903 - accuracy: 0.5627\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5210\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5106\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.6898 - accuracy: 0.5314\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5419\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5210\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5731\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5523\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5523\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5419\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6832 - accuracy: 0.5419\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5523\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 992us/step - loss: 0.6811 - accuracy: 0.5314\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.5523\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5210\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5314\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.5419\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.5627\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.5857\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.5544\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5774\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 966us/step - loss: 0.6545 - accuracy: 0.6108\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6108\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.6449 - accuracy: 0.6525\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.6494 - accuracy: 0.6256\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6716\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6820\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.7176\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6967\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.6238 - accuracy: 0.7176\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.7510\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.7657\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.7783\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.8096\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7679\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.8013\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.8139\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.5750 - accuracy: 0.8243\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.8243\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.8451\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8117\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8243\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.8347\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.8473\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8494\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.8703\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.5175 - accuracy: 0.9037\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.5107 - accuracy: 0.8911\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.8933\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8933\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8933\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.9037\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8933\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8911\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8599\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8703\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8703\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8933\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.9037\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8933\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.9015\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8829\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8933\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8724\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8724\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.4088 - accuracy: 0.8829\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8829\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8829\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.4087 - accuracy: 0.8829\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.9037\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8933\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3523 - accuracy: 0.9141\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8933\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8829\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.3650 - accuracy: 0.8807\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8703\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8390\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8703\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3653 - accuracy: 0.8829\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8829\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3218 - accuracy: 0.9037\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3267 - accuracy: 0.8933\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8933\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.3179 - accuracy: 0.8933\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.9037\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3155 - accuracy: 0.8829\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3448 - accuracy: 0.8829\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.3180 - accuracy: 0.8933\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3415 - accuracy: 0.8703\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8703\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8703\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3368 - accuracy: 0.8724\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9245\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8829\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8829\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8724\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8724\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8829\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3241 - accuracy: 0.8724\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8620\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8933\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.3007 - accuracy: 0.8933\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2803 - accuracy: 0.8933\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8933\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2781 - accuracy: 0.8933\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.9037\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2879 - accuracy: 0.8933\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3119 - accuracy: 0.8724\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2959 - accuracy: 0.8829\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9037\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2813 - accuracy: 0.8933\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.3166 - accuracy: 0.8620\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2866 - accuracy: 0.8829\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.3083 - accuracy: 0.8724\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2770 - accuracy: 0.8724\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2976 - accuracy: 0.8724\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.9037\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8933\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2493 - accuracy: 0.8933\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8620\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2853 - accuracy: 0.8829\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2871 - accuracy: 0.8829\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8829\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8933\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2624 - accuracy: 0.8933\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.2439 - accuracy: 0.9037\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8724\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8829\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8829\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2688 - accuracy: 0.8829\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2635 - accuracy: 0.8933\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9141\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8724\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8829\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9037\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8724\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2477 - accuracy: 0.8933\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.9037\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9037\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8933\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2426 - accuracy: 0.8829\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.8829\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 980us/step - loss: 0.2357 - accuracy: 0.8933\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 988us/step - loss: 0.2669 - accuracy: 0.8620\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2470 - accuracy: 0.8829\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2249 - accuracy: 0.9037\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2268 - accuracy: 0.8933\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.8933\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2293 - accuracy: 0.8829\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2510 - accuracy: 0.8829\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2553 - accuracy: 0.8954\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2275 - accuracy: 0.9059\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2205 - accuracy: 0.9163\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2596 - accuracy: 0.8850\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.8954\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2341 - accuracy: 0.8829\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.8933\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8724\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.8933\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2419 - accuracy: 0.8829\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 978us/step - loss: 0.2487 - accuracy: 0.8829\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9037\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.8933\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2515 - accuracy: 0.8620\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2413 - accuracy: 0.8954\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2084 - accuracy: 0.9163\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 993us/step - loss: 0.2440 - accuracy: 0.8850\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9059\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2289 - accuracy: 0.9059\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2009 - accuracy: 0.9163\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.2347 - accuracy: 0.9059\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.2267 - accuracy: 0.8954\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2127 - accuracy: 0.8933\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.1827 - accuracy: 0.9141\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.8829\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.8829\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9037\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2248 - accuracy: 0.8829\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.8724\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2305 - accuracy: 0.8954\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.8933\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9037\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2298 - accuracy: 0.8724\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.8829\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.8829\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.8933\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9163\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3215 - accuracy: 0.8889\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.3758\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6073\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.6177\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.6281\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6177\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.6073\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6489\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.6281\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5968\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.6802\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6177\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.6177\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.6177\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6073\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6073\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6281\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.6281\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.6281\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.6844 - accuracy: 0.6281\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.6073\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.6281\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 986us/step - loss: 0.6812 - accuracy: 0.6177\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6281\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.6281\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.6385\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.6281\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6385\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.6177\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6696 - accuracy: 0.6073\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6385\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6385\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6698\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 993us/step - loss: 0.6562 - accuracy: 0.6281\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6489\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6501 - accuracy: 0.6281\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6073\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6593\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6385\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6073\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6385\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6281\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6385\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6281\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6281\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6281\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.5968\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.5968\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.6281\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6281\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.6489\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.5679 - accuracy: 0.6489\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 994us/step - loss: 0.5739 - accuracy: 0.6177\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6528\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.6632\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.6632\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.6879\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7523\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 988us/step - loss: 0.5457 - accuracy: 0.7002\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7334\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7126\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7581\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8245\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8557\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.8245\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.4786 - accuracy: 0.8472\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8140\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.8492\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8492\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8387\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8719\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8738\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.4268 - accuracy: 0.8947\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8843\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.9070\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.9279\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.9174\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.9070\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8966\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.9174\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.9070\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8862\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.9070\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.9070\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.9070\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8966\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.9174\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8966\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.9174\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.9279\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8966\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.9279\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8862\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8843\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8947\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9051\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8947\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8634\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8843\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2962 - accuracy: 0.8947\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2776 - accuracy: 0.9051\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8947\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8738\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.2708 - accuracy: 0.8947\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8843\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.2902 - accuracy: 0.8947\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9051\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8843\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8843\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2735 - accuracy: 0.8947\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.8947\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8634\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8966\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9070\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.9279\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.9070\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2646 - accuracy: 0.9174\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3071 - accuracy: 0.8966\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.90 - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9070\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2605 - accuracy: 0.9070\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2817 - accuracy: 0.8966\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.8862\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8862\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9174\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.9174\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9051\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2935 - accuracy: 0.8738\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2527 - accuracy: 0.9051\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8843\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.8927\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8719\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8511\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8738\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9051\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.8947\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.2543 - accuracy: 0.8823\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2562 - accuracy: 0.8719\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.8823\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9032\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.2775 - accuracy: 0.8511\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.2610 - accuracy: 0.8719\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.8927\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8823\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8615\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2661 - accuracy: 0.8615\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8615\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8615\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2335 - accuracy: 0.8823\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2474 - accuracy: 0.8719\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.2704 - accuracy: 0.8615\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2717 - accuracy: 0.8615\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8719\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8511\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.8823\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8407\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2655 - accuracy: 0.8615\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8719\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8719\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2628 - accuracy: 0.8615\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8615\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.8823\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 990us/step - loss: 0.2190 - accuracy: 0.8927\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2335 - accuracy: 0.8823\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2659 - accuracy: 0.8615\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.8823\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8492\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2668 - accuracy: 0.8387\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2441 - accuracy: 0.8596\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2494 - accuracy: 0.8596\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8492\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8387\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2496 - accuracy: 0.8719\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.8927\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9051\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8843\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8947\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.8947\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8843\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8615\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 993us/step - loss: 0.2581 - accuracy: 0.8387\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.8492\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8492\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8492\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2538 - accuracy: 0.8387\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8492\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 994us/step - loss: 0.2297 - accuracy: 0.8596\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.8804\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2342 - accuracy: 0.8700\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8387\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.8492\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2168 - accuracy: 0.9051\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2317 - accuracy: 0.8947\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.8843\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2574 - accuracy: 0.8387\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2135 - accuracy: 0.8700\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2220 - accuracy: 0.8700\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8387\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2401 - accuracy: 0.8596\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2387 - accuracy: 0.8492\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8492\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8492\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4383 - accuracy: 0.9231\n",
      "Accuracy mean: 0.8632478713989258\n",
      "Accuracy variance: 0.06202717880168738\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 200)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names.append(\"RNN\")\n",
    "method_scores.append(0.887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Method Score')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.ylim([0.60,0.90])\n",
    "plt.bar(method_names,method_scores,width=0.5)\n",
    "plt.xlabel('Method Name')\n",
    "plt.ylabel('Method Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
